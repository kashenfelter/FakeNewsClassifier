{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and set up logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-26 17:40:05,742 : INFO : loading projection weights from ./GoogleNews-vectors-negative300.bin\n",
      "2018-10-26 17:40:57,022 : INFO : loaded (3000000, 300) matrix from ./GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_feature_vector(words, model, num_features):\n",
    "    #function to average all words vectors in a given paragraph\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "\n",
    "    for word in words:\n",
    "        nwords = nwords+1\n",
    "        featureVec = np.add(featureVec, model.wv.get_vector(word))\n",
    "\n",
    "    if nwords>0:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"agreeDisagreeDiscuss.csv\", sep=',', error_bad_lines=False, encoding= \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spider burrowed through tourists stomach and u...</td>\n",
       "      <td>Fear not arachnophobes the story of Bunburys s...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nasa Confirms Earth Will Experience 6 Days of ...</td>\n",
       "      <td>Thousands of people have been duped by a fake ...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Banksy Arrested  Real Identity Revealed Is The...</td>\n",
       "      <td>If youve seen a story floating around on your ...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gateway Pundit</td>\n",
       "      <td>A British rapper whose father is awaiting tria...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Woman detained in Lebanon is not alBaghdadis w...</td>\n",
       "      <td>An Iraqi official denied that a woman detained...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soon Marijuana May Lead to Ticket Not Arrest i...</td>\n",
       "      <td>After campaigning on a promise to reform stopa...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boko Haram Denies Nigeria CeaseFire Claim</td>\n",
       "      <td>ABUJA Nigeria  The leader of Nigerias Islamist...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No Robert Plant Didnt Rip Up an $800 Million C...</td>\n",
       "      <td>Led Zeppelin fans will be disappointed to lear...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ISIL Beheads American Photojournalist in Iraq</td>\n",
       "      <td>James Foley an American journalist who went mi...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Boko Haram ceasefire ignored as violence flare...</td>\n",
       "      <td>CNN  Boko Haram laughed off Nigerias announcem...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NET Extra Backfromthedead Catholic priest clai...</td>\n",
       "      <td>A 71 years old cleric Father John Micheal Onea...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rumor debunked RoboCopstyle robots are not pat...</td>\n",
       "      <td>Knightscope cofounder Stacy Stephens said rumo...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Report Christian Bale Just Bailed on the Steve...</td>\n",
       "      <td>Christian Bale is in talks to play Steve Jobs ...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Insurgents killed in Nigeria despite alleged t...</td>\n",
       "      <td>Boko Haram has reportedly agreed to a ceasefir...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Report ISIS Leader Abu Bakr AlBaghdadi Assassi...</td>\n",
       "      <td>An unverified photo claims to show the body of...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fisherman lands 19 STONE catfish which could b...</td>\n",
       "      <td>Dino Ferrari hooked the whopper wels catfish w...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Student accidentally sets college on fire duri...</td>\n",
       "      <td>He popped the question  and burned down his co...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pope Francis turns out not to have made pets i...</td>\n",
       "      <td>NEW YORK  Pope Francis has given hope to gays ...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Macaulay Culkin Hasnt Died Despite What Everyo...</td>\n",
       "      <td>Claim Actor Macaulay Culkin has diedFALSEExamp...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>No its not Tiger Woods selling an island in La...</td>\n",
       "      <td>A luxury island previously owned by Tiger Wood...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Islamic State leaders family detained by Leban...</td>\n",
       "      <td>Iraqs Interior Ministry said on Wednesday that...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Indian civil servant sacked after 24year sickie</td>\n",
       "      <td>An Indian public official has been sacked for ...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Moment Michael Brown was shot dead caught on a...</td>\n",
       "      <td>FERGUSON St Louis CNN  Could a newly released ...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Soldier Gunman Killed In Shooting Incident Nea...</td>\n",
       "      <td>A gunman opened fire at Canadas National War M...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Canadian official identifies dead Ottawa gunma...</td>\n",
       "      <td>THE young soldier killed in a terror attack on...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mystery woman behind the richest hands on the ...</td>\n",
       "      <td>The identity of the couple behind the megasucc...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Apple 12Inch MacBook Air Details Emerge Device...</td>\n",
       "      <td>Our Retina MacBook Air rumour article brings t...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Islamic State militants allegedly used chlorin...</td>\n",
       "      <td>BAGHDAD  Nina Vice President Osama Nujaifi con...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Audio Reveals Pause in Gunfire When Michae...</td>\n",
       "      <td>Video messaging app Glide on Thursday said it ...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20461</th>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>Yet more bad news for Obamacare this week Moli...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20462</th>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>Congressional Republicans evidently hoping tha...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20463</th>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>Did Obamacare workIts worth reflecting upon af...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20464</th>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>Millions may lose coverage next year if Congre...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20465</th>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>Come November the grim trudge across the incre...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20466</th>\n",
       "      <td>A Sign That Obamacare Exchanges Are Failing</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20467</th>\n",
       "      <td>Republicans call Obamacare a failure These 7 c...</td>\n",
       "      <td>Yet more bad news for Obamacare this week Moli...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20468</th>\n",
       "      <td>Republicans call Obamacare a failure These 7 c...</td>\n",
       "      <td>Congressional Republicans evidently hoping tha...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>Republicans call Obamacare a failure These 7 c...</td>\n",
       "      <td>Did Obamacare workIts worth reflecting upon af...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20470</th>\n",
       "      <td>Republicans call Obamacare a failure These 7 c...</td>\n",
       "      <td>Millions may lose coverage next year if Congre...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>Republicans call Obamacare a failure These 7 c...</td>\n",
       "      <td>Come November the grim trudge across the incre...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>Republicans call Obamacare a failure These 7 c...</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20473</th>\n",
       "      <td>CBOs Alternate Facts Show Obamacare is Unsusta...</td>\n",
       "      <td>Yet more bad news for Obamacare this week Moli...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20474</th>\n",
       "      <td>CBOs Alternate Facts Show Obamacare is Unsusta...</td>\n",
       "      <td>Congressional Republicans evidently hoping tha...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>CBOs Alternate Facts Show Obamacare is Unsusta...</td>\n",
       "      <td>Did Obamacare workIts worth reflecting upon af...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>CBOs Alternate Facts Show Obamacare is Unsusta...</td>\n",
       "      <td>Millions may lose coverage next year if Congre...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>CBOs Alternate Facts Show Obamacare is Unsusta...</td>\n",
       "      <td>Come November the grim trudge across the incre...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>CBOs Alternate Facts Show Obamacare is Unsusta...</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>Yet more bad news for Obamacare this week Moli...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20480</th>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>Congressional Republicans evidently hoping tha...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20481</th>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>Did Obamacare workIts worth reflecting upon af...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20482</th>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>Millions may lose coverage next year if Congre...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20483</th>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>Come November the grim trudge across the incre...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>Why Obamacare failed</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20485</th>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>Yet more bad news for Obamacare this week Moli...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>Congressional Republicans evidently hoping tha...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20487</th>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>Did Obamacare workIts worth reflecting upon af...</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20488</th>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>Millions may lose coverage next year if Congre...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20489</th>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>Come November the grim trudge across the incre...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20490</th>\n",
       "      <td>The success of the Affordable Care Act is a hu...</td>\n",
       "      <td>Remember how much Republicans wanted to repeal...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20491 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Headline  \\\n",
       "0      Hundreds of Palestinians flee floods in Gaza a...   \n",
       "1      Spider burrowed through tourists stomach and u...   \n",
       "2      Nasa Confirms Earth Will Experience 6 Days of ...   \n",
       "3      Banksy Arrested  Real Identity Revealed Is The...   \n",
       "4                                         Gateway Pundit   \n",
       "5      Woman detained in Lebanon is not alBaghdadis w...   \n",
       "6      Soon Marijuana May Lead to Ticket Not Arrest i...   \n",
       "7              Boko Haram Denies Nigeria CeaseFire Claim   \n",
       "8      No Robert Plant Didnt Rip Up an $800 Million C...   \n",
       "9          ISIL Beheads American Photojournalist in Iraq   \n",
       "10     Boko Haram ceasefire ignored as violence flare...   \n",
       "11     NET Extra Backfromthedead Catholic priest clai...   \n",
       "12     Rumor debunked RoboCopstyle robots are not pat...   \n",
       "13     Report Christian Bale Just Bailed on the Steve...   \n",
       "14     Insurgents killed in Nigeria despite alleged t...   \n",
       "15     Report ISIS Leader Abu Bakr AlBaghdadi Assassi...   \n",
       "16     Fisherman lands 19 STONE catfish which could b...   \n",
       "17     Student accidentally sets college on fire duri...   \n",
       "18     Pope Francis turns out not to have made pets i...   \n",
       "19     Macaulay Culkin Hasnt Died Despite What Everyo...   \n",
       "20     No its not Tiger Woods selling an island in La...   \n",
       "21     Islamic State leaders family detained by Leban...   \n",
       "22       Indian civil servant sacked after 24year sickie   \n",
       "23     Moment Michael Brown was shot dead caught on a...   \n",
       "24     Soldier Gunman Killed In Shooting Incident Nea...   \n",
       "25     Canadian official identifies dead Ottawa gunma...   \n",
       "26     Mystery woman behind the richest hands on the ...   \n",
       "27     Apple 12Inch MacBook Air Details Emerge Device...   \n",
       "28     Islamic State militants allegedly used chlorin...   \n",
       "29     New Audio Reveals Pause in Gunfire When Michae...   \n",
       "...                                                  ...   \n",
       "20461        A Sign That Obamacare Exchanges Are Failing   \n",
       "20462        A Sign That Obamacare Exchanges Are Failing   \n",
       "20463        A Sign That Obamacare Exchanges Are Failing   \n",
       "20464        A Sign That Obamacare Exchanges Are Failing   \n",
       "20465        A Sign That Obamacare Exchanges Are Failing   \n",
       "20466        A Sign That Obamacare Exchanges Are Failing   \n",
       "20467  Republicans call Obamacare a failure These 7 c...   \n",
       "20468  Republicans call Obamacare a failure These 7 c...   \n",
       "20469  Republicans call Obamacare a failure These 7 c...   \n",
       "20470  Republicans call Obamacare a failure These 7 c...   \n",
       "20471  Republicans call Obamacare a failure These 7 c...   \n",
       "20472  Republicans call Obamacare a failure These 7 c...   \n",
       "20473  CBOs Alternate Facts Show Obamacare is Unsusta...   \n",
       "20474  CBOs Alternate Facts Show Obamacare is Unsusta...   \n",
       "20475  CBOs Alternate Facts Show Obamacare is Unsusta...   \n",
       "20476  CBOs Alternate Facts Show Obamacare is Unsusta...   \n",
       "20477  CBOs Alternate Facts Show Obamacare is Unsusta...   \n",
       "20478  CBOs Alternate Facts Show Obamacare is Unsusta...   \n",
       "20479                               Why Obamacare failed   \n",
       "20480                               Why Obamacare failed   \n",
       "20481                               Why Obamacare failed   \n",
       "20482                               Why Obamacare failed   \n",
       "20483                               Why Obamacare failed   \n",
       "20484                               Why Obamacare failed   \n",
       "20485  The success of the Affordable Care Act is a hu...   \n",
       "20486  The success of the Affordable Care Act is a hu...   \n",
       "20487  The success of the Affordable Care Act is a hu...   \n",
       "20488  The success of the Affordable Care Act is a hu...   \n",
       "20489  The success of the Affordable Care Act is a hu...   \n",
       "20490  The success of the Affordable Care Act is a hu...   \n",
       "\n",
       "                                                    Body    Stance  \n",
       "0      Hundreds of Palestinians were evacuated from t...     agree  \n",
       "1      Fear not arachnophobes the story of Bunburys s...  disagree  \n",
       "2      Thousands of people have been duped by a fake ...     agree  \n",
       "3      If youve seen a story floating around on your ...     agree  \n",
       "4      A British rapper whose father is awaiting tria...   discuss  \n",
       "5      An Iraqi official denied that a woman detained...     agree  \n",
       "6      After campaigning on a promise to reform stopa...   discuss  \n",
       "7      ABUJA Nigeria  The leader of Nigerias Islamist...   discuss  \n",
       "8      Led Zeppelin fans will be disappointed to lear...     agree  \n",
       "9      James Foley an American journalist who went mi...   discuss  \n",
       "10     CNN  Boko Haram laughed off Nigerias announcem...   discuss  \n",
       "11     A 71 years old cleric Father John Micheal Onea...     agree  \n",
       "12     Knightscope cofounder Stacy Stephens said rumo...     agree  \n",
       "13     Christian Bale is in talks to play Steve Jobs ...   discuss  \n",
       "14     Boko Haram has reportedly agreed to a ceasefir...   discuss  \n",
       "15     An unverified photo claims to show the body of...   discuss  \n",
       "16     Dino Ferrari hooked the whopper wels catfish w...     agree  \n",
       "17     He popped the question  and burned down his co...     agree  \n",
       "18     NEW YORK  Pope Francis has given hope to gays ...  disagree  \n",
       "19     Claim Actor Macaulay Culkin has diedFALSEExamp...     agree  \n",
       "20     A luxury island previously owned by Tiger Wood...  disagree  \n",
       "21     Iraqs Interior Ministry said on Wednesday that...   discuss  \n",
       "22     An Indian public official has been sacked for ...     agree  \n",
       "23     FERGUSON St Louis CNN  Could a newly released ...   discuss  \n",
       "24     A gunman opened fire at Canadas National War M...     agree  \n",
       "25     THE young soldier killed in a terror attack on...   discuss  \n",
       "26     The identity of the couple behind the megasucc...     agree  \n",
       "27     Our Retina MacBook Air rumour article brings t...   discuss  \n",
       "28     BAGHDAD  Nina Vice President Osama Nujaifi con...   discuss  \n",
       "29     Video messaging app Glide on Thursday said it ...     agree  \n",
       "...                                                  ...       ...  \n",
       "20461  Yet more bad news for Obamacare this week Moli...     agree  \n",
       "20462  Congressional Republicans evidently hoping tha...  disagree  \n",
       "20463  Did Obamacare workIts worth reflecting upon af...   discuss  \n",
       "20464  Millions may lose coverage next year if Congre...     agree  \n",
       "20465  Come November the grim trudge across the incre...     agree  \n",
       "20466  Remember how much Republicans wanted to repeal...  disagree  \n",
       "20467  Yet more bad news for Obamacare this week Moli...  disagree  \n",
       "20468  Congressional Republicans evidently hoping tha...     agree  \n",
       "20469  Did Obamacare workIts worth reflecting upon af...   discuss  \n",
       "20470  Millions may lose coverage next year if Congre...  disagree  \n",
       "20471  Come November the grim trudge across the incre...  disagree  \n",
       "20472  Remember how much Republicans wanted to repeal...     agree  \n",
       "20473  Yet more bad news for Obamacare this week Moli...     agree  \n",
       "20474  Congressional Republicans evidently hoping tha...  disagree  \n",
       "20475  Did Obamacare workIts worth reflecting upon af...   discuss  \n",
       "20476  Millions may lose coverage next year if Congre...     agree  \n",
       "20477  Come November the grim trudge across the incre...     agree  \n",
       "20478  Remember how much Republicans wanted to repeal...  disagree  \n",
       "20479  Yet more bad news for Obamacare this week Moli...     agree  \n",
       "20480  Congressional Republicans evidently hoping tha...  disagree  \n",
       "20481  Did Obamacare workIts worth reflecting upon af...   discuss  \n",
       "20482  Millions may lose coverage next year if Congre...     agree  \n",
       "20483  Come November the grim trudge across the incre...     agree  \n",
       "20484  Remember how much Republicans wanted to repeal...  disagree  \n",
       "20485  Yet more bad news for Obamacare this week Moli...  disagree  \n",
       "20486  Congressional Republicans evidently hoping tha...     agree  \n",
       "20487  Did Obamacare workIts worth reflecting upon af...   discuss  \n",
       "20488  Millions may lose coverage next year if Congre...  disagree  \n",
       "20489  Come November the grim trudge across the incre...  disagree  \n",
       "20490  Remember how much Republicans wanted to repeal...     agree  \n",
       "\n",
       "[20491 rows x 3 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "samp1filt = list(filter(lambda x: x in model.vocab, df.Headline[2].split()))\n",
    "sentence_1_avg_vector = avg_feature_vector(samp1filt, model=model, num_features=300)\n",
    "samp2filt = list(filter(lambda x: x in model.vocab, df.Body[2].split()))\n",
    "sentence_2_avg_vector = avg_feature_vector(samp2filt, model=model, num_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"rel_df.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/home/saad/.local/lib/python3.6/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "rel = []\n",
    "for i in range(len(df)):\n",
    "    stopHeadline = [w for w in df.Headline[i].split() if not w in stop_words] \n",
    "    samp1filt = list(filter(lambda x: x in model.vocab, stopHeadline))\n",
    "    sentence_1_avg_vector = avg_feature_vector(samp1filt, model=model, num_features=300)\n",
    "    \n",
    "    stopBody = [w for w in df.Body[i].split() if not w in stop_words] \n",
    "    samp2filt = list(filter(lambda x: x in model.vocab, stopBody))\n",
    "    sentence_2_avg_vector = avg_feature_vector(samp2filt, model=model, num_features=300)\n",
    "    \n",
    "    rel.append(1 - spatial.distance.cosine(sentence_1_avg_vector, sentence_2_avg_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Relevancy'] = rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"rel_df.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sentence_2 = \"Hundreds Palestinians flee floods in Gaza as Israel opens dams\"\n",
    "sentence_2_avg_vector = avg_feature_vector(sentence_2.split(), model=model, num_features=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sentence_1 = \"Hundreds Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened number dams near the flooding the Gaza Valley in the wake recent severe winter\"\n",
    "sentence_1_avg_vector = avg_feature_vector(sentence_1.split(), model=model, num_features=300)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sentence_1_avg_vector = avg_feature_vector(words, model=model, num_features=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "embded = avg_feature_vector(list(filter(lambda x: x in model.vocab, df.Body[0].split())), model=model, num_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "embeddings =pandas.DataFrame((avg_feature_vector(list(filter(lambda x: x in model.vocab, df.Body[0].split())), model=model, num_features=300)).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042348</td>\n",
       "      <td>0.050587</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>-0.034364</td>\n",
       "      <td>-0.032291</td>\n",
       "      <td>-0.00525</td>\n",
       "      <td>-0.082431</td>\n",
       "      <td>0.074518</td>\n",
       "      <td>0.072256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105168</td>\n",
       "      <td>-0.008516</td>\n",
       "      <td>-0.106848</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>-0.022616</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>-0.058478</td>\n",
       "      <td>-0.03246</td>\n",
       "      <td>0.052244</td>\n",
       "      <td>-0.012583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5        6    \\\n",
       "0  0.042348  0.050587  0.010934  0.027728 -0.034364 -0.032291 -0.00525   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0 -0.082431  0.074518  0.072256    ...    -0.105168 -0.008516 -0.106848   \n",
       "\n",
       "        293       294       295       296      297       298       299  \n",
       "0  0.001479 -0.022616  0.038849 -0.058478 -0.03246  0.052244 -0.012583  \n",
       "\n",
       "[1 rows x 300 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for sents in df.Body:\n",
    "    filtered_list = list(filter(lambda x: x in model.vocab, sents.split()))\n",
    "    avg_embed = avg_feature_vector(filtered_list, model=model, num_features=300)\n",
    "    avg_embed_trans = avg_embed.reshape(1,-1)\n",
    "    temp_df = pandas.DataFrame(avg_embed_trans)\n",
    "    embeddings = embeddings.append(temp_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.to_csv(\"ADD_embeddings.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = sentence_1_avg_vector.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sentence_2_avg_vector.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(sentence_1_avg_vector.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pandas.DataFrame(sentence_2_avg_vector.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = list(filter(lambda x: x in model.vocab, df.Headline[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4982364773750305"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - spatial.distance.cosine(sentence_1_avg_vector, sentence_2_avg_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/.conda/envs/textVAE2/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "w1= \"polite\"\n",
    "vect = model.wv.get_vector(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8127754926681519),\n",
       " ('dismayed', 0.78623366355896),\n",
       " ('amazed', 0.7840966582298279),\n",
       " ('appalled', 0.7795482277870178),\n",
       " ('stunned', 0.7516888976097107),\n",
       " ('astonished', 0.7505988478660583),\n",
       " ('surprised', 0.720969557762146),\n",
       " ('suprised', 0.7207925319671631),\n",
       " ('astounded', 0.7204748392105103),\n",
       " ('surprized', 0.6929066777229309)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w1 = \"shocked\"\n",
    "model.wv.most_similar (positive=w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9174547791481018),\n",
       " ('friendly', 0.8309274911880493),\n",
       " ('cordial', 0.7990915179252625),\n",
       " ('professional', 0.7945970892906189),\n",
       " ('attentive', 0.7732747197151184),\n",
       " ('gracious', 0.7469891309738159)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada', 0.6603403091430664),\n",
       " ('germany', 0.6510637998580933),\n",
       " ('spain', 0.6431018114089966),\n",
       " ('barcelona', 0.61174076795578),\n",
       " ('mexico', 0.6070996522903442),\n",
       " ('rome', 0.6065913438796997)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.80775386095047),\n",
       " ('amazed', 0.7797470092773438),\n",
       " ('astonished', 0.7748459577560425),\n",
       " ('dismayed', 0.7680633068084717),\n",
       " ('stunned', 0.7603034973144531),\n",
       " ('appalled', 0.7466776371002197)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duvet', 0.7086508274078369),\n",
       " ('blanket', 0.7016597390174866),\n",
       " ('mattress', 0.7002605199813843),\n",
       " ('quilt', 0.6868821978569031),\n",
       " ('matress', 0.6777950525283813),\n",
       " ('pillowcase', 0.6413239240646362),\n",
       " ('sheets', 0.6382123827934265),\n",
       " ('foam', 0.6322235465049744),\n",
       " ('pillows', 0.6320573687553406),\n",
       " ('comforter', 0.5972476601600647)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76181122646029453"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25355593501920781"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
